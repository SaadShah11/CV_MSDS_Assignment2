{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jneY_6DH2Acd",
        "outputId": "2a0f1e4a-b5a1-44bc-d544-989e7fe47774"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=10oRO0YPelxqjlD1cl8IgKiYRRoo1I5rQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvEIHlqc2JnC",
        "outputId": "760653fe-8143-4ae6-d540-b7d0a06d9578"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=10oRO0YPelxqjlD1cl8IgKiYRRoo1I5rQ\n",
            "From (redirected): https://drive.google.com/uc?id=10oRO0YPelxqjlD1cl8IgKiYRRoo1I5rQ&confirm=t&uuid=da72a381-8d55-4938-bcde-a4a0dbaeec26\n",
            "To: /content/test_set.tar\n",
            "100% 52.2M/52.2M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Kr3PP-PTgWh"
      },
      "outputs": [],
      "source": [
        "!tar -xvf test_set.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yc08hNWs78Gc"
      },
      "outputs": [],
      "source": [
        "data_path = \"/content/val_set/\"\n",
        "data_annotations_path = \"/content/val_set/annotations/\"\n",
        "data_images_path = \"/content/val_set/images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WRBo0lxL8DDl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFOf4LPJrixT"
      },
      "source": [
        "# Data Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVBn_uiVg-rd"
      },
      "source": [
        "### Loading dataset and transforming it into *DataFrames*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZuEVE_Ky78Gc"
      },
      "outputs": [],
      "source": [
        "def dataset_tp_csv(data_annotations_path, data_images_path):\n",
        "  data = []\n",
        "  for i in range(3998):\n",
        "      try:\n",
        "          arrousal = np.load(data_annotations_path + '{index}_aro.npy'.format(index=i))\n",
        "      except FileNotFoundError:\n",
        "          arrousal = None\n",
        "          \n",
        "      try:\n",
        "          expression = np.load(data_annotations_path + '{index}_exp.npy'.format(index=i))\n",
        "      except FileNotFoundError:\n",
        "          expression = None\n",
        "          \n",
        "      try:\n",
        "          valence = np.load(data_annotations_path + '{index}_val.npy'.format(index=i))\n",
        "      except FileNotFoundError:\n",
        "          valence = None\n",
        "          \n",
        "      try:\n",
        "          landmarks = np.load(data_annotations_path + '{index}_lnd.npy'.format(index=i))\n",
        "      except FileNotFoundError:\n",
        "          landmarks = None\n",
        "          \n",
        "      image_path = '{path}/{index}.jpg'.format(path=data_images_path, index=i)\n",
        "      if os.path.isfile(image_path):\n",
        "          data.append((i, expression, valence, arrousal, landmarks, image_path))\n",
        "      else:\n",
        "          print('Image file not found for index', i)\n",
        "  return pd.DataFrame.from_records(data, columns=['image_index', 'expression', 'valence', 'arousal', 'landmarks', 'image_path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsEKbkgh78Gd"
      },
      "outputs": [],
      "source": [
        "df_test = dataset_tp_csv(data_annotations_path, data_images_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QfVydLudNC-"
      },
      "source": [
        "### Transforming Dataframes into *Dataloaders*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1X_MoIaP7MT4"
      },
      "outputs": [],
      "source": [
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define transformation pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Define dataset class\n",
        "class FacialExpressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, transform):\n",
        "        self.df = df\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.df.loc[idx, 'image_path']\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        # landmarks = self.df.loc[idx, 'landmarks']\n",
        "        # landmarks = torch.tensor(self.df.loc[idx, 'landmarks'], dtype=torch.float32)\n",
        "        # expression = self.df.loc[idx, 'expression']\n",
        "        expression_arr = int(self.df.loc[idx, 'expression'].item())\n",
        "        expression = torch.tensor(expression_arr, dtype=torch.int32)\n",
        "        # valence = self.df.loc[idx, 'valence']\n",
        "        valence_arr = float(self.df.loc[idx, 'valence'].item())\n",
        "        valence = torch.tensor(valence_arr, dtype=torch.float32)\n",
        "        # arousal = self.df.loc[idx, 'arousal']\n",
        "        arousal_arr = float(self.df.loc[idx, 'arousal'].item())\n",
        "        arousal = torch.tensor(arousal_arr, dtype=torch.float32)\n",
        "        # return img, landmarks, expression, valence, arousal\n",
        "        return img, expression, valence, arousal\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Sju5UTq1hydQ"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Define the AffectNet dataset and dataloaders\n",
        "test_dataset = FacialExpressionDataset(df_test, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbt9gsJeh6F1"
      },
      "source": [
        "# FineTuning Models for Facial Expression recognition, and computing Valence and Arousal Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WONjlWat9XZ3"
      },
      "source": [
        "### 1):EffecientNET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "X-HpeFz0X6k8"
      },
      "outputs": [],
      "source": [
        "# Define the EfficientNet model\n",
        "class EfficientNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(EfficientNetModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.layer1 = torchvision.models.efficientnet_b0(pretrained=True).features\n",
        "        self.layer2 = torchvision.models.efficientnet_b0(pretrained=True).avgpool\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(1280, 8),\n",
        "        )\n",
        "\n",
        "        self.arousal = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(1280, 1),\n",
        "        )\n",
        "\n",
        "        self.valence = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(1280, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        feature = torch.flatten(x, 1)\n",
        "        logits = self.classifier(feature)\n",
        "\n",
        "        valence = self.valence(feature)\n",
        "        arousal = self.arousal(feature)\n",
        "\n",
        "        return logits, valence, arousal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MliJtF8OdeYH"
      },
      "outputs": [],
      "source": [
        "model_EfficientNet = EfficientNetModel()\n",
        "model_EfficientNet.load_state_dict(torch.load(\"EfficientNet_model.pth\"))\n",
        "model_EfficientNet.to(device)\n",
        "model_EfficientNet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "_P5Dbfe6djQ_"
      },
      "outputs": [],
      "source": [
        "# Define the loss functions\n",
        "classification_loss = F.cross_entropy\n",
        "regression_loss = F.mse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yMkVQxP4OWM",
        "outputId": "235555e1-fc66-44d9-ebd2-bc708022b752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2918\n",
            "EfficientNet model classification loss: 3.590598021205604\n",
            "EfficientNet model regression loss for valence: 0.19078590933838635\n",
            "EfficientNet model regression loss for arousal: 0.14018409192112719\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    test_loss_EfficientNet_classification = 0\n",
        "    test_loss_EfficientNet_regression_valence = 0\n",
        "    test_loss_EfficientNet_regression_arousal = 0\n",
        "    num_samples = 0\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate EfficientNet model\n",
        "        output_expression, output_valence, output_arousal = model_EfficientNet(images)\n",
        "        test_loss_EfficientNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        test_loss_EfficientNet_regression_valence += regression_loss(output_valence, valences).item() * batch_size\n",
        "        test_loss_EfficientNet_regression_arousal += regression_loss(output_arousal, arousals).item() * batch_size\n",
        "        \n",
        "\n",
        "    print(num_samples)\n",
        "    # Compute the average test\n",
        "    test_loss_EfficientNet_classification /= num_samples\n",
        "    test_loss_EfficientNet_regression_valence /= num_samples\n",
        "    test_loss_EfficientNet_regression_arousal /= num_samples\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"EfficientNet model classification loss:\", test_loss_EfficientNet_classification)\n",
        "    print(\"EfficientNet model regression loss for valence:\", test_loss_EfficientNet_regression_valence)\n",
        "    print(\"EfficientNet model regression loss for arousal:\", test_loss_EfficientNet_regression_arousal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    test_loss_EfficientNet_classification = 0\n",
        "    num_samples = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, expressions, _, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate EfficientNet model\n",
        "        output_expression, _, _ = model_EfficientNet(images)\n",
        "        test_loss_EfficientNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        \n",
        "        # Collect true and predicted labels\n",
        "        y_true.extend(expressions.cpu().numpy())\n",
        "        y_pred.extend(output_expression.argmax(dim=1).cpu().numpy())\n",
        "        \n",
        "\n",
        "    # Compute the average test loss\n",
        "    test_loss_EfficientNet_classification /= num_samples\n",
        "    \n",
        "    # Compute classification metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    # Print the test results\n",
        "    print(\"EfficientNet model classification loss:\", test_loss_EfficientNet_classification)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"F1-Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FlifGTMjpFd",
        "outputId": "0af05c27-df02-45d5-a28b-681ea833e2e8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.70      0.43       355\n",
            "           1       0.47      0.94      0.63       378\n",
            "           2       0.52      0.52      0.52       364\n",
            "           3       0.56      0.41      0.47       369\n",
            "           4       0.74      0.37      0.50       361\n",
            "           5       0.81      0.24      0.38       361\n",
            "           6       0.52      0.57      0.55       375\n",
            "           7       0.80      0.07      0.12       355\n",
            "\n",
            "    accuracy                           0.48      2918\n",
            "   macro avg       0.59      0.48      0.45      2918\n",
            "weighted avg       0.59      0.48      0.45      2918\n",
            "\n",
            "EfficientNet model classification loss: 3.590598021205604\n",
            "Accuracy: 0.48252227553118576\n",
            "F1-Score: 0.4522966400984679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install krippendorff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeSHzaVGkocc",
        "outputId": "3afef3d2-8694-4add-b6f4-72119b1c81e7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting krippendorff\n",
            "  Downloading krippendorff-0.6.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from krippendorff) (1.22.4)\n",
            "Installing collected packages: krippendorff\n",
            "Successfully installed krippendorff-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score, roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import krippendorff\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    num_samples = 0\n",
        "    true_expressions, pred_expressions = [], []\n",
        "    true_valences, pred_valences = [], []\n",
        "    true_arousals, pred_arousals = [], []\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate EfficientNet model\n",
        "        output_expression, output_valence, output_arousal = model_EfficientNet(images)\n",
        "        _, predicted_expression = torch.max(output_expression.data, 1)\n",
        "        true_expressions.extend(expressions.cpu().numpy())\n",
        "        pred_expressions.extend(predicted_expression.cpu().numpy())\n",
        "        true_valences.extend(valences.cpu().numpy())\n",
        "        pred_valences.extend(output_valence.cpu().numpy())\n",
        "        true_arousals.extend(arousals.cpu().numpy())\n",
        "        pred_arousals.extend(output_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics for classification task\n",
        "    cohen_kappa = cohen_kappa_score(true_expressions, pred_expressions)\n",
        "    alpha = krippendorff.alpha(reliability_data=[true_expressions, pred_expressions])\n",
        "    # roc_auc = roc_auc_score(true_expressions, pred_expressions)\n",
        "    # precision, recall, _ = precision_recall_curve(true_expressions, pred_expressions)\n",
        "    # pr_auc = auc(recall, precision)\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"Cohen's Kappa for classification:\", cohen_kappa)\n",
        "    print(\"Krippendorff's Alpha for classification:\", alpha)\n",
        "    # print(\"ROC AUC for classification:\", roc_auc)\n",
        "    # print(\"AUC-PR for classification:\", pr_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsheeH3LkjdZ",
        "outputId": "6a2a1709-6532-4aed-e648-96fe40c1edf5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa for classification: 0.40812615236730454\n",
            "Krippendorff's Alpha for classification: 0.22502347897785457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, \\\n",
        "    mean_absolute_error, mean_squared_log_error\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loss_EfficientNet_classification = 0\n",
        "    test_loss_EfficientNet_regression_valence = 0\n",
        "    test_loss_EfficientNet_regression_arousal = 0\n",
        "    num_samples = 0\n",
        "    predictions_valence = []\n",
        "    targets_valence = []\n",
        "    predictions_arousal = []\n",
        "    targets_arousal = []\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate EfficientNet model\n",
        "        output_expression, output_valence, output_arousal = model_EfficientNet(images)\n",
        "        test_loss_EfficientNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        test_loss_EfficientNet_regression_valence += regression_loss(output_valence, valences).item() * batch_size\n",
        "        test_loss_EfficientNet_regression_arousal += regression_loss(output_arousal, arousals).item() * batch_size\n",
        "\n",
        "        # Collect predictions and targets for regression evaluation\n",
        "        predictions_valence.append(output_valence.cpu().numpy())\n",
        "        targets_valence.append(valences.cpu().numpy())\n",
        "        predictions_arousal.append(output_arousal.cpu().numpy())\n",
        "        targets_arousal.append(arousals.cpu().numpy())\n",
        "\n",
        "    # Combine predictions and targets for regression evaluation\n",
        "    predictions_valence = np.concatenate(predictions_valence)\n",
        "    targets_valence = np.concatenate(targets_valence)\n",
        "    predictions_arousal = np.concatenate(predictions_arousal)\n",
        "    targets_arousal = np.concatenate(targets_arousal)\n",
        "\n",
        "    # Compute the average test\n",
        "    test_loss_EfficientNet_classification /= num_samples\n",
        "    test_loss_EfficientNet_regression_valence /= num_samples\n",
        "    test_loss_EfficientNet_regression_arousal /= num_samples\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"EfficientNet model classification loss:\", test_loss_EfficientNet_classification)\n",
        "    print(\"EfficientNet model regression loss for valence:\", test_loss_EfficientNet_regression_valence)\n",
        "    print(\"EfficientNet model regression loss for arousal:\", test_loss_EfficientNet_regression_arousal)\n",
        "    \n",
        "    # Compute regression metrics\n",
        "    print(\"RMSE for valence:\", mean_squared_error(targets_valence, predictions_valence, squared=False))\n",
        "    print(\"Correlation for valence:\", pearsonr(targets_valence.ravel(), predictions_valence.ravel())[0])\n",
        "    print(\"Sign Agreement Metric for valence:\", np.mean(np.sign(targets_valence) == np.sign(predictions_valence)))\n",
        "    print(\"Correlation Coefficient for valence:\", spearmanr(targets_valence.ravel(), predictions_valence.ravel())[0])\n",
        "    \n",
        "    print(\"RMSE for arousal:\", mean_squared_error(targets_arousal, predictions_arousal, squared=False))\n",
        "    print(\"Correlation for arousal:\", pearsonr(targets_arousal.ravel(), predictions_arousal.ravel())[0])\n",
        "    print(\"Sign Agreement Metric for arousal:\", np.mean(np.sign(targets_arousal) == np.sign(predictions_arousal)))\n",
        "    print(\"Correlation Coefficient for arousal:\", spearmanr(targets_arousal.ravel(), predictions_arousal.ravel())[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddlrGuJ7n-l0",
        "outputId": "43e165a3-f37e-4cdc-9120-14862821fc73"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EfficientNet model classification loss: 3.590598021205604\n",
            "EfficientNet model regression loss for valence: 0.19078590933838635\n",
            "EfficientNet model regression loss for arousal: 0.14018409192112719\n",
            "RMSE for valence: 0.43679047\n",
            "Correlation for valence: 0.5994073229886933\n",
            "Sign Agreement Metric for valence: 0.7200137080191912\n",
            "Correlation Coefficient for valence: 0.5563749148804865\n",
            "RMSE for arousal: 0.37441167\n",
            "Correlation for arousal: 0.5151686677268523\n",
            "Sign Agreement Metric for arousal: 0.7587388622344071\n",
            "Correlation Coefficient for arousal: 0.49731038884621076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu6dCoq7iP3y"
      },
      "source": [
        "### 2): Mobile Net V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "sTqRethMgGer"
      },
      "outputs": [],
      "source": [
        "# Define the EfficientNet model\n",
        "class MobileNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(MobileNetModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.layer1 = torchvision.models.mobilenet_v3_small(pretrained=True).features\n",
        "        self.layer2 = torchvision.models.mobilenet_v3_small(pretrained=True).avgpool\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(576, 8),\n",
        "        )\n",
        "\n",
        "        self.arousal = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(576, 1),\n",
        "        )\n",
        "\n",
        "        self.valence = nn.Sequential(\n",
        "            nn.Dropout(p=0.2, inplace=False),\n",
        "            nn.Linear(576, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        feature = torch.flatten(x, 1)\n",
        "        logits = self.classifier(feature)\n",
        "        valence = self.valence(feature)\n",
        "        arousal = self.arousal(feature)\n",
        "\n",
        "        return logits, valence, arousal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "flMHIlhNa0yo"
      },
      "outputs": [],
      "source": [
        "# Define the loss functions\n",
        "classification_loss = F.cross_entropy\n",
        "regression_loss = F.mse_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba71dda3-e8dc-46d6-8d15-36db9357e671",
        "id": "yrED1aCTq3Pt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet model classification loss: 2.703925766270401\n",
            "MobileNet model regression loss for valence: 0.1820510380720749\n",
            "MobileNet model regression loss for arousal: 0.14822316902030241\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    test_loss_MobileNet_classification = 0\n",
        "    test_loss_MobileNet_regression_valence = 0\n",
        "    test_loss_MobileNet_regression_arousal = 0\n",
        "    num_samples = 0\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate MobileNet model\n",
        "        output_expression, output_valence, output_arousal = model_MobileNet(images)\n",
        "        test_loss_MobileNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        test_loss_MobileNet_regression_valence += regression_loss(output_valence, valences).item() * batch_size\n",
        "        test_loss_MobileNet_regression_arousal += regression_loss(output_arousal, arousals).item() * batch_size\n",
        "\n",
        "    # Compute the average test\n",
        "    test_loss_MobileNet_classification /= num_samples\n",
        "    test_loss_MobileNet_regression_valence /= num_samples\n",
        "    test_loss_MobileNet_regression_arousal /= num_samples\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"MobileNet model classification loss:\", test_loss_MobileNet_classification)\n",
        "    print(\"MobileNet model regression loss for valence:\", test_loss_MobileNet_regression_valence)\n",
        "    print(\"MobileNet model regression loss for arousal:\", test_loss_MobileNet_regression_arousal)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    test_loss_MobileNet_classification = 0\n",
        "    num_samples = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, expressions, _, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate MobileNet model\n",
        "        output_expression, _, _ = model_MobileNet(images)\n",
        "        test_loss_MobileNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        \n",
        "        # Collect true and predicted labels\n",
        "        y_true.extend(expressions.cpu().numpy())\n",
        "        y_pred.extend(output_expression.argmax(dim=1).cpu().numpy())\n",
        "        \n",
        "\n",
        "    # Compute the average test loss\n",
        "    test_loss_MobileNet_classification /= num_samples\n",
        "    \n",
        "    # Compute classification metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    \n",
        "    # Print the test results\n",
        "    print(\"MobileNet model classification loss:\", test_loss_MobileNet_classification)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"F1-Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4eca8d-62a4-4834-8886-c1be5960d6a8",
        "id": "uJwXZHC3q3Pu"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.72      0.43       355\n",
            "           1       0.49      0.93      0.64       378\n",
            "           2       0.49      0.54      0.51       364\n",
            "           3       0.56      0.36      0.44       369\n",
            "           4       0.67      0.38      0.48       361\n",
            "           5       0.74      0.21      0.33       361\n",
            "           6       0.46      0.48      0.47       375\n",
            "           7       0.75      0.03      0.06       355\n",
            "\n",
            "    accuracy                           0.46      2918\n",
            "   macro avg       0.56      0.46      0.42      2918\n",
            "weighted avg       0.56      0.46      0.42      2918\n",
            "\n",
            "MobileNet model classification loss: 2.703925766270401\n",
            "Accuracy: 0.4602467443454421\n",
            "F1-Score: 0.4236166392793974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install krippendorff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f4e6c4f-497b-4fa5-e97e-2299be5be845",
        "id": "wFHoB88Nq3Pu"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: krippendorff in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.10/dist-packages (from krippendorff) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score, roc_auc_score, precision_recall_curve, auc\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import krippendorff\n",
        "\n",
        "# Evaluate the models on the test set\n",
        "with torch.no_grad():\n",
        "    num_samples = 0\n",
        "    true_expressions, pred_expressions = [], []\n",
        "    true_valences, pred_valences = [], []\n",
        "    true_arousals, pred_arousals = [], []\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate MobileNet model\n",
        "        output_expression, output_valence, output_arousal = model_MobileNet(images)\n",
        "        _, predicted_expression = torch.max(output_expression.data, 1)\n",
        "        true_expressions.extend(expressions.cpu().numpy())\n",
        "        pred_expressions.extend(predicted_expression.cpu().numpy())\n",
        "        true_valences.extend(valences.cpu().numpy())\n",
        "        pred_valences.extend(output_valence.cpu().numpy())\n",
        "        true_arousals.extend(arousals.cpu().numpy())\n",
        "        pred_arousals.extend(output_arousal.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics for classification task\n",
        "    cohen_kappa = cohen_kappa_score(true_expressions, pred_expressions)\n",
        "    alpha = krippendorff.alpha(reliability_data=[true_expressions, pred_expressions])\n",
        "    # roc_auc = roc_auc_score(true_expressions, pred_expressions)\n",
        "    # precision, recall, _ = precision_recall_curve(true_expressions, pred_expressions)\n",
        "    # pr_auc = auc(recall, precision)\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"Cohen's Kappa for classification:\", cohen_kappa)\n",
        "    print(\"Krippendorff's Alpha for classification:\", alpha)\n",
        "    # print(\"ROC AUC for classification:\", roc_auc)\n",
        "    # print(\"AUC-PR for classification:\", pr_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "724e678c-5906-445a-9952-4fde8790ad74",
        "id": "natUelRlq3Pu"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa for classification: 0.38274150153970454\n",
            "Krippendorff's Alpha for classification: 0.15785437454744822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score, \\\n",
        "    mean_absolute_error, mean_squared_log_error\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_loss_MobileNet_classification = 0\n",
        "    test_loss_MobileNet_regression_valence = 0\n",
        "    test_loss_MobileNet_regression_arousal = 0\n",
        "    num_samples = 0\n",
        "    predictions_valence = []\n",
        "    targets_valence = []\n",
        "    predictions_arousal = []\n",
        "    targets_arousal = []\n",
        "    for images, expressions, valences, arousals in test_loader:\n",
        "        images = images.to(device)\n",
        "        expressions = expressions.to(device)\n",
        "        expressions = expressions.type(torch.LongTensor).to(device)\n",
        "        valences = valences.to(device)\n",
        "        arousals = arousals.to(device)\n",
        "        valences = valences.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        arousals = arousals.view(-1, 1)  # Reshape target tensor to (batch_size, 1)\n",
        "        batch_size = images.size(0)\n",
        "        num_samples += batch_size\n",
        "        \n",
        "        # Evaluate MobileNet model\n",
        "        output_expression, output_valence, output_arousal = model_MobileNet(images)\n",
        "        test_loss_MobileNet_classification += classification_loss(output_expression, expressions).item() * batch_size\n",
        "        test_loss_MobileNet_regression_valence += regression_loss(output_valence, valences).item() * batch_size\n",
        "        test_loss_MobileNet_regression_arousal += regression_loss(output_arousal, arousals).item() * batch_size\n",
        "\n",
        "        # Collect predictions and targets for regression evaluation\n",
        "        predictions_valence.append(output_valence.cpu().numpy())\n",
        "        targets_valence.append(valences.cpu().numpy())\n",
        "        predictions_arousal.append(output_arousal.cpu().numpy())\n",
        "        targets_arousal.append(arousals.cpu().numpy())\n",
        "\n",
        "    # Combine predictions and targets for regression evaluation\n",
        "    predictions_valence = np.concatenate(predictions_valence)\n",
        "    targets_valence = np.concatenate(targets_valence)\n",
        "    predictions_arousal = np.concatenate(predictions_arousal)\n",
        "    targets_arousal = np.concatenate(targets_arousal)\n",
        "\n",
        "    # Compute the average test\n",
        "    test_loss_MobileNet_classification /= num_samples\n",
        "    test_loss_MobileNet_regression_valence /= num_samples\n",
        "    test_loss_MobileNet_regression_arousal /= num_samples\n",
        "\n",
        "    # Print the test results\n",
        "    print(\"MobileNet model classification loss:\", test_loss_MobileNet_classification)\n",
        "    print(\"MobileNet model regression loss for valence:\", test_loss_MobileNet_regression_valence)\n",
        "    print(\"MobileNet model regression loss for arousal:\", test_loss_MobileNet_regression_arousal)\n",
        "    \n",
        "    # Compute regression metrics\n",
        "    print(\"RMSE for valence:\", mean_squared_error(targets_valence, predictions_valence, squared=False))\n",
        "    print(\"Correlation for valence:\", pearsonr(targets_valence.ravel(), predictions_valence.ravel())[0])\n",
        "    print(\"Sign Agreement Metric for valence:\", np.mean(np.sign(targets_valence) == np.sign(predictions_valence)))\n",
        "    print(\"Correlation Coefficient for valence:\", spearmanr(targets_valence.ravel(), predictions_valence.ravel())[0])\n",
        "    \n",
        "    print(\"RMSE for arousal:\", mean_squared_error(targets_arousal, predictions_arousal, squared=False))\n",
        "    print(\"Correlation for arousal:\", pearsonr(targets_arousal.ravel(), predictions_arousal.ravel())[0])\n",
        "    print(\"Sign Agreement Metric for arousal:\", np.mean(np.sign(targets_arousal) == np.sign(predictions_arousal)))\n",
        "    print(\"Correlation Coefficient for arousal:\", spearmanr(targets_arousal.ravel(), predictions_arousal.ravel())[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80713ae-6dfb-43cc-ae96-31b7cd61d0af",
        "id": "BYL23I9aq3Pu"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet model classification loss: 2.703925766270401\n",
            "MobileNet model regression loss for valence: 0.1820510380720749\n",
            "MobileNet model regression loss for arousal: 0.14822316902030241\n",
            "RMSE for valence: 0.4266744\n",
            "Correlation for valence: 0.5883723132835436\n",
            "Sign Agreement Metric for valence: 0.7388622344071282\n",
            "Correlation Coefficient for valence: 0.536732794216031\n",
            "RMSE for arousal: 0.3849976\n",
            "Correlation for arousal: 0.4819521835987085\n",
            "Sign Agreement Metric for arousal: 0.747429746401645\n",
            "Correlation Coefficient for arousal: 0.47646464088177215\n"
          ]
        }
      ]
    }
  ]
}